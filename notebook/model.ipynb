{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tensorflow import keras \n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,\\\n",
    "    Flatten, Conv2D, MaxPool2D\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model   \n",
    "import cv2\n",
    "from PIL import Image    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(validation_split):\n",
    "    \n",
    "    # Load data from csv file into data frame, drop all rows that have missing values\n",
    "    data_frame = pd.read_csv('../data/training.csv')\n",
    "    print(f'Number of samples: {data_frame[\"Image\"].count()}')\n",
    "    data_frame = data_frame.dropna()\n",
    "    print(f'Number of samples without any missing value: {data_frame[\"Image\"].count()}')\n",
    "\n",
    "    # Convert the rows of the image column from pixel values separated by spaces to numpy arrays\n",
    "    data_frame[\"Image\"] = data_frame[\"Image\"].apply(lambda img: np.fromstring(img, sep=\" \"))\n",
    "\n",
    "    # Create numpy matrix from image column by stacking the rows vertically\n",
    "    X_data = np.vstack(data_frame[\"Image\"].values)\n",
    "\n",
    "    # Normalize pixel values to (0, 1) range\n",
    "    X_data = X_data / 255\n",
    "\n",
    "    # Convert to float32, which is the default for Keras\n",
    "    X_data = X_data.astype(\"float32\")\n",
    "\n",
    "    # Reshape each row from one dimensional arrays to (height, width, num_channels) = (96, 96, 1)\n",
    "    X_data = X_data.reshape(-1, 96, 96, 1)\n",
    "\n",
    "    # Extract labels representing the coordinates of facial landmarks\n",
    "    Y_data = data_frame[data_frame.columns[:-1]].values\n",
    "\n",
    "    # Normalize coordinates to (0, 1) range\n",
    "    Y_data = Y_data / 96\n",
    "    Y_data = Y_data.astype(\"float32\")\n",
    "\n",
    "    # Shuffle data\n",
    "    X_data, Y_data = shuffle(X_data, Y_data)\n",
    "\n",
    "    # Split data into training set and validation set\n",
    "    split_index = int(X_data.shape[0] * (1 - validation_split))\n",
    "    X_train = X_data[:split_index]\n",
    "    Y_train = Y_data[:split_index]\n",
    "    X_val = X_data[split_index:]\n",
    "    Y_val = Y_data[split_index:]\n",
    "\n",
    "    return X_train, Y_train, X_val, Y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['left_eye_center_x',\n",
       " 'left_eye_center_y',\n",
       " 'right_eye_center_x',\n",
       " 'right_eye_center_y',\n",
       " 'left_eye_inner_corner_x',\n",
       " 'left_eye_inner_corner_y',\n",
       " 'left_eye_outer_corner_x',\n",
       " 'left_eye_outer_corner_y',\n",
       " 'right_eye_inner_corner_x',\n",
       " 'right_eye_inner_corner_y',\n",
       " 'right_eye_outer_corner_x',\n",
       " 'right_eye_outer_corner_y',\n",
       " 'left_eyebrow_inner_end_x',\n",
       " 'left_eyebrow_inner_end_y',\n",
       " 'left_eyebrow_outer_end_x',\n",
       " 'left_eyebrow_outer_end_y',\n",
       " 'right_eyebrow_inner_end_x',\n",
       " 'right_eyebrow_inner_end_y',\n",
       " 'right_eyebrow_outer_end_x',\n",
       " 'right_eyebrow_outer_end_y',\n",
       " 'nose_tip_x',\n",
       " 'nose_tip_y',\n",
       " 'mouth_left_corner_x',\n",
       " 'mouth_left_corner_y',\n",
       " 'mouth_right_corner_x',\n",
       " 'mouth_right_corner_y',\n",
       " 'mouth_center_top_lip_x',\n",
       " 'mouth_center_top_lip_y',\n",
       " 'mouth_center_bottom_lip_x',\n",
       " 'mouth_center_bottom_lip_y',\n",
       " 'Image']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get columns names to search for needed columns index \n",
    "target_variables_feature_name = list(data.columns)\n",
    "target_variables_feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'left_eyebrow_outer_end_y'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_variables_feature_name[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_eye_outer_corner_x index: 6\n",
      " left_eye_outer_corner_y index: 7\n",
      " right_eye_outer_corner_x index: 10\n",
      " right_eye_outer_corner_y index: 11\n",
      " left_eyebrow_outer_end_y index: 19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f'left_eye_outer_corner_x index: {target_variables_feature_name.index(\"left_eye_outer_corner_x\")}\\n',\n",
    "    f'left_eye_outer_corner_y index: {target_variables_feature_name.index(\"left_eye_outer_corner_y\")}\\n', #4\n",
    "    f'right_eye_outer_corner_x index: {target_variables_feature_name.index(\"right_eye_outer_corner_x\")}\\n',\n",
    "    f'right_eye_outer_corner_y index: {target_variables_feature_name.index(\"right_eye_outer_corner_y\")}\\n',\n",
    "    f'left_eyebrow_outer_end_y index: {target_variables_feature_name.index(\"right_eyebrow_outer_end_y\")}\\n',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 7049\n",
      "Number of samples without any missing value: 2140\n"
     ]
    }
   ],
   "source": [
    "#split the data into train and test \n",
    "X_train, y_train, X_val, y_val = load_data(validation_split = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.708875  , 0.37780148, 0.30892646, ..., 0.6785956 , 0.48741913,\n",
       "        0.8240294 ],\n",
       "       [0.7011118 , 0.39410558, 0.32081988, ..., 0.7022236 , 0.49569565,\n",
       "        0.82713664],\n",
       "       [0.6832875 , 0.381525  , 0.32855   , ..., 0.708325  , 0.53524375,\n",
       "        0.86195   ],\n",
       "       ...,\n",
       "       [0.67078733, 0.4090699 , 0.3596746 , ..., 0.839437  , 0.47497538,\n",
       "        0.8574032 ],\n",
       "       [0.6754487 , 0.3689263 , 0.30589104, ..., 0.69551283, 0.5178846 ,\n",
       "        0.8244295 ],\n",
       "       [0.65833664, 0.38317   , 0.31077334, ..., 0.77008   , 0.49767   ,\n",
       "        0.83729666]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#landmarks\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.4627451 ],\n",
       "         [0.49019608],\n",
       "         [0.4117647 ],\n",
       "         ...,\n",
       "         [0.9490196 ],\n",
       "         [0.68235296],\n",
       "         [0.50980395]],\n",
       "\n",
       "        [[0.4862745 ],\n",
       "         [0.4745098 ],\n",
       "         [0.4       ],\n",
       "         ...,\n",
       "         [0.972549  ],\n",
       "         [0.72156864],\n",
       "         [0.52156866]],\n",
       "\n",
       "        [[0.49019608],\n",
       "         [0.44313726],\n",
       "         [0.39607844],\n",
       "         ...,\n",
       "         [1.        ],\n",
       "         [0.8509804 ],\n",
       "         [0.57254905]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.45490196],\n",
       "         [0.34901962],\n",
       "         [0.29803923],\n",
       "         ...,\n",
       "         [0.4117647 ],\n",
       "         [0.56078434],\n",
       "         [0.75686276]],\n",
       "\n",
       "        [[0.34509805],\n",
       "         [0.3764706 ],\n",
       "         [0.3372549 ],\n",
       "         ...,\n",
       "         [0.49803922],\n",
       "         [0.6039216 ],\n",
       "         [0.7411765 ]],\n",
       "\n",
       "        [[0.28235295],\n",
       "         [0.33333334],\n",
       "         [0.32941177],\n",
       "         ...,\n",
       "         [0.5254902 ],\n",
       "         [0.65882355],\n",
       "         [0.7529412 ]]],\n",
       "\n",
       "\n",
       "       [[[0.25490198],\n",
       "         [0.28235295],\n",
       "         [0.3137255 ],\n",
       "         ...,\n",
       "         [0.654902  ],\n",
       "         [0.6509804 ],\n",
       "         [0.654902  ]],\n",
       "\n",
       "        [[0.26666668],\n",
       "         [0.28627452],\n",
       "         [0.3137255 ],\n",
       "         ...,\n",
       "         [0.6666667 ],\n",
       "         [0.67058825],\n",
       "         [0.654902  ]],\n",
       "\n",
       "        [[0.2627451 ],\n",
       "         [0.28627452],\n",
       "         [0.32156864],\n",
       "         ...,\n",
       "         [0.6666667 ],\n",
       "         [0.6627451 ],\n",
       "         [0.6627451 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.42745098],\n",
       "         [0.43137255],\n",
       "         [0.4745098 ],\n",
       "         ...,\n",
       "         [0.61960787],\n",
       "         [0.6156863 ],\n",
       "         [0.5411765 ]],\n",
       "\n",
       "        [[0.3647059 ],\n",
       "         [0.3254902 ],\n",
       "         [0.5137255 ],\n",
       "         ...,\n",
       "         [0.61960787],\n",
       "         [0.654902  ],\n",
       "         [0.6784314 ]],\n",
       "\n",
       "        [[0.41960785],\n",
       "         [0.41960785],\n",
       "         [0.5764706 ],\n",
       "         ...,\n",
       "         [0.6156863 ],\n",
       "         [0.654902  ],\n",
       "         [0.654902  ]]],\n",
       "\n",
       "\n",
       "       [[[0.9411765 ],\n",
       "         [0.9411765 ],\n",
       "         [0.9411765 ],\n",
       "         ...,\n",
       "         [0.84705883],\n",
       "         [0.8509804 ],\n",
       "         [0.85490197]],\n",
       "\n",
       "        [[0.94509804],\n",
       "         [0.9411765 ],\n",
       "         [0.93333334],\n",
       "         ...,\n",
       "         [0.8509804 ],\n",
       "         [0.85490197],\n",
       "         [0.8509804 ]],\n",
       "\n",
       "        [[0.9411765 ],\n",
       "         [0.9372549 ],\n",
       "         [0.93333334],\n",
       "         ...,\n",
       "         [0.84705883],\n",
       "         [0.85490197],\n",
       "         [0.85490197]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.36862746],\n",
       "         [0.32941177],\n",
       "         [0.36078432],\n",
       "         ...,\n",
       "         [0.4862745 ],\n",
       "         [0.48235294],\n",
       "         [0.4862745 ]],\n",
       "\n",
       "        [[0.36078432],\n",
       "         [0.29803923],\n",
       "         [0.34117648],\n",
       "         ...,\n",
       "         [0.49411765],\n",
       "         [0.4862745 ],\n",
       "         [0.47058824]],\n",
       "\n",
       "        [[0.3764706 ],\n",
       "         [0.30588236],\n",
       "         [0.3529412 ],\n",
       "         ...,\n",
       "         [0.4745098 ],\n",
       "         [0.4627451 ],\n",
       "         [0.4509804 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.05098039],\n",
       "         [0.04705882],\n",
       "         [0.05098039],\n",
       "         ...,\n",
       "         [0.19215687],\n",
       "         [0.16470589],\n",
       "         [0.14901961]],\n",
       "\n",
       "        [[0.05882353],\n",
       "         [0.05098039],\n",
       "         [0.05098039],\n",
       "         ...,\n",
       "         [0.20784314],\n",
       "         [0.18431373],\n",
       "         [0.16470589]],\n",
       "\n",
       "        [[0.05882353],\n",
       "         [0.04705882],\n",
       "         [0.04705882],\n",
       "         ...,\n",
       "         [0.2       ],\n",
       "         [0.17254902],\n",
       "         [0.14901961]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.04705882],\n",
       "         [0.04705882],\n",
       "         [0.04705882],\n",
       "         ...,\n",
       "         [0.39215687],\n",
       "         [0.34509805],\n",
       "         [0.29803923]],\n",
       "\n",
       "        [[0.05098039],\n",
       "         [0.04705882],\n",
       "         [0.04705882],\n",
       "         ...,\n",
       "         [0.36078432],\n",
       "         [0.32156864],\n",
       "         [0.30588236]],\n",
       "\n",
       "        [[0.05098039],\n",
       "         [0.04705882],\n",
       "         [0.04705882],\n",
       "         ...,\n",
       "         [0.34901962],\n",
       "         [0.31764707],\n",
       "         [0.32941177]]],\n",
       "\n",
       "\n",
       "       [[[0.9019608 ],\n",
       "         [0.89411765],\n",
       "         [0.8901961 ],\n",
       "         ...,\n",
       "         [0.68235296],\n",
       "         [0.6862745 ],\n",
       "         [0.68235296]],\n",
       "\n",
       "        [[0.8901961 ],\n",
       "         [0.8862745 ],\n",
       "         [0.8862745 ],\n",
       "         ...,\n",
       "         [0.68235296],\n",
       "         [0.6862745 ],\n",
       "         [0.6745098 ]],\n",
       "\n",
       "        [[0.8901961 ],\n",
       "         [0.8862745 ],\n",
       "         [0.8784314 ],\n",
       "         ...,\n",
       "         [0.6784314 ],\n",
       "         [0.6862745 ],\n",
       "         [0.6784314 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.38431373],\n",
       "         [0.3882353 ],\n",
       "         [0.39607844],\n",
       "         ...,\n",
       "         [0.43137255],\n",
       "         [0.41960785],\n",
       "         [0.4117647 ]],\n",
       "\n",
       "        [[0.38039216],\n",
       "         [0.38431373],\n",
       "         [0.38431373],\n",
       "         ...,\n",
       "         [0.44313726],\n",
       "         [0.43529412],\n",
       "         [0.42745098]],\n",
       "\n",
       "        [[0.38039216],\n",
       "         [0.3764706 ],\n",
       "         [0.38431373],\n",
       "         ...,\n",
       "         [0.42352942],\n",
       "         [0.41568628],\n",
       "         [0.40392157]]],\n",
       "\n",
       "\n",
       "       [[[1.        ],\n",
       "         [0.99607843],\n",
       "         [0.99607843],\n",
       "         ...,\n",
       "         [0.99607843],\n",
       "         [1.        ],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[0.99607843],\n",
       "         [1.        ],\n",
       "         [0.91764706],\n",
       "         ...,\n",
       "         [0.99607843],\n",
       "         [1.        ],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[0.99215686],\n",
       "         [1.        ],\n",
       "         [0.78431374],\n",
       "         ...,\n",
       "         [0.99215686],\n",
       "         [1.        ],\n",
       "         [1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.99607843],\n",
       "         [1.        ],\n",
       "         [0.972549  ],\n",
       "         ...,\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[0.99607843],\n",
       "         [1.        ],\n",
       "         [0.76862746],\n",
       "         ...,\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.92156863],\n",
       "         [0.64705884],\n",
       "         ...,\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#images\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(96, 96, 1), activation=\"relu\", padding=\"same\"))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (5, 5), activation=\"relu\", padding=\"same\"))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (5, 5), activation=\"relu\", padding=\"same\"))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    model.add(Dense(30))\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(X_train, Y_train, X_val, Y_val, model, model_name, num_epochs):\n",
    "    results_file = open(\"../output/results.txt\", \"w\")\n",
    "    histories = []\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, \n",
    "        Y_train, \n",
    "        batch_size = 200, \n",
    "        epochs = num_epochs, \n",
    "        validation_data = (X_val, Y_val)\n",
    "    )           \n",
    "        \n",
    "    histories.append(history)\n",
    "\n",
    "    # Evaluate\n",
    "    final_train_loss = model.evaluate(X_train, Y_train, verbose=0)\n",
    "    final_val_loss = model.evaluate(X_val, Y_val, verbose=0)\n",
    "    results_file.write(model_name + \" => final_train_loss: \" + str(final_train_loss) + \", final_val_loss: \" + str(final_val_loss) + \"\\n\")\n",
    "\n",
    "    # Save model\n",
    "    model.save(\"../models/facial_landmark_model\")       \n",
    "        \n",
    "    results_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "10/10 [==============================] - 22s 494ms/step - loss: 0.4715 - val_loss: 0.0837\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.0395 - val_loss: 0.0170\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.0162 - val_loss: 0.0124\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.0112 - val_loss: 0.0067\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 9.8747e-04 - val_loss: 0.0012\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 9.1890e-04 - val_loss: 0.0010\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 9.4702e-04 - val_loss: 9.8122e-04\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 8.6560e-04 - val_loss: 9.5567e-04\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 8.2613e-04 - val_loss: 0.0011\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 8.8375e-04 - val_loss: 8.9750e-04\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 8.1698e-04 - val_loss: 0.0010\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 8.0272e-04 - val_loss: 8.3991e-04\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 7.4233e-04 - val_loss: 7.6539e-04\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 7.7826e-04 - val_loss: 7.5690e-04\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 6.2542e-04 - val_loss: 7.5273e-04\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 7.5367e-04 - val_loss: 9.8000e-04\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 7.5733e-04 - val_loss: 7.2797e-04\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 5.8560e-04 - val_loss: 7.4566e-04\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 5.6907e-04 - val_loss: 6.0664e-04\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 5.3550e-04 - val_loss: 8.8471e-04\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 5.6819e-04 - val_loss: 6.0007e-04\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 4.8687e-04 - val_loss: 6.9211e-04\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 5.1645e-04 - val_loss: 6.5127e-04\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 5.1410e-04 - val_loss: 5.8203e-04\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 5.6494e-04 - val_loss: 5.5189e-04\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 4.5467e-04 - val_loss: 5.3993e-04\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 4.4233e-04 - val_loss: 5.7541e-04\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 4.6939e-04 - val_loss: 6.8787e-04\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 5.1451e-04 - val_loss: 8.7279e-04\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 6.3015e-04 - val_loss: 9.9179e-04\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 5.6489e-04 - val_loss: 5.6172e-04\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - 3s 333ms/step - loss: 4.6979e-04 - val_loss: 5.8614e-04\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - 3s 344ms/step - loss: 4.6167e-04 - val_loss: 6.0014e-04\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 4.4271e-04 - val_loss: 5.3528e-04\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 3.9788e-04 - val_loss: 4.9205e-04\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - 4s 354ms/step - loss: 4.4363e-04 - val_loss: 6.5186e-04\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 4.9535e-04 - val_loss: 4.9866e-04\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 3.7666e-04 - val_loss: 5.9672e-04\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 4.3749e-04 - val_loss: 6.0064e-04\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 4.0773e-04 - val_loss: 4.8180e-04\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 3.5410e-04 - val_loss: 5.9314e-04\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 4.0553e-04 - val_loss: 4.8539e-04\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 3.9063e-04 - val_loss: 5.1862e-04\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 3.7625e-04 - val_loss: 6.0835e-04\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - 3s 347ms/step - loss: 4.4558e-04 - val_loss: 5.0214e-04\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 5.8065e-04 - val_loss: 5.0035e-04\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 3.7569e-04 - val_loss: 8.6830e-04\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 5.5271e-04 - val_loss: 5.9990e-04\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 4.0712e-04 - val_loss: 6.6078e-04\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 4.6389e-04 - val_loss: 4.7227e-04\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 3.4581e-04 - val_loss: 4.6514e-04\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 3.6620e-04 - val_loss: 4.7165e-04\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 3.5552e-04 - val_loss: 5.1653e-04\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 3.4295e-04 - val_loss: 4.4901e-04\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 3.0894e-04 - val_loss: 5.5935e-04\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 4.1253e-04 - val_loss: 4.6739e-04\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 3.4244e-04 - val_loss: 5.2542e-04\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 3.4475e-04 - val_loss: 5.8884e-04\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 3.8455e-04 - val_loss: 4.8208e-04\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 3.3192e-04 - val_loss: 4.4636e-04\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 3.0129e-04 - val_loss: 4.5073e-04\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 3.6032e-04 - val_loss: 4.3617e-04\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 3.0636e-04 - val_loss: 4.4579e-04\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 3.0888e-04 - val_loss: 5.1492e-04\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 3.9554e-04 - val_loss: 4.4030e-04\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 2.9696e-04 - val_loss: 5.2129e-04\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 3.4238e-04 - val_loss: 4.5965e-04\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 3.0879e-04 - val_loss: 4.6176e-04\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 3.2830e-04 - val_loss: 5.1424e-04\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 3.5338e-04 - val_loss: 6.3293e-04\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 3.7426e-04 - val_loss: 6.5384e-04\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 4.1144e-04 - val_loss: 6.2240e-04\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 3.8408e-04 - val_loss: 4.5733e-04\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 3.0446e-04 - val_loss: 4.3000e-04\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 2.9768e-04 - val_loss: 4.6434e-04\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 2.8461e-04 - val_loss: 5.1035e-04\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 3.4508e-04 - val_loss: 0.0010\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 8.3787e-04 - val_loss: 5.0330e-04\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 8.5555e-04 - val_loss: 0.0012\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 6.0552e-04 - val_loss: 4.7416e-04\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 3.2021e-04 - val_loss: 6.0649e-04\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 3.5787e-04 - val_loss: 6.3356e-04\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 3.3975e-04 - val_loss: 4.3872e-04\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 2.8619e-04 - val_loss: 4.1797e-04\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 2.7448e-04 - val_loss: 4.3270e-04\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 2.7031e-04 - val_loss: 4.2261e-04\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 2.6075e-04 - val_loss: 4.3064e-04\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 2.6545e-04 - val_loss: 4.1306e-04\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 2.5199e-04 - val_loss: 4.1064e-04\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 2.4545e-04 - val_loss: 4.1989e-04\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 2.4580e-04 - val_loss: 5.2456e-04\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 3.9314e-04 - val_loss: 7.3124e-04\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 4.0641e-04 - val_loss: 7.4726e-04\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 3.9514e-04 - val_loss: 5.8406e-04\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 3.2394e-04 - val_loss: 4.5247e-04\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 2.8016e-04 - val_loss: 4.4648e-04\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 2.7958e-04 - val_loss: 4.7125e-04\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 2.8471e-04 - val_loss: 4.4243e-04\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 2.8009e-04 - val_loss: 4.8270e-04\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 2.9401e-04 - val_loss: 3.9689e-04\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 2.4628e-04 - val_loss: 4.2298e-04\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 2.4154e-04 - val_loss: 4.3778e-04\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 2.4522e-04 - val_loss: 4.4732e-04\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 3.0560e-04 - val_loss: 6.4921e-04\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - 4s 353ms/step - loss: 3.5181e-04 - val_loss: 5.5281e-04\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - 3s 349ms/step - loss: 3.7378e-04 - val_loss: 4.1271e-04\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 2.9337e-04 - val_loss: 4.4805e-04\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 2.3266e-04 - val_loss: 4.8932e-04\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 2.5914e-04 - val_loss: 4.6620e-04\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 2.3245e-04 - val_loss: 4.2246e-04\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 2.2183e-04 - val_loss: 4.2049e-04\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 2.1947e-04 - val_loss: 4.1350e-04\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 2.2272e-04 - val_loss: 4.1381e-04\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 2.2255e-04 - val_loss: 4.1275e-04\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 2.3169e-04 - val_loss: 4.1490e-04\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 2.1136e-04 - val_loss: 4.2028e-04\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 2.0998e-04 - val_loss: 4.5563e-04\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 2.1013e-04 - val_loss: 5.4759e-04\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 3.0268e-04 - val_loss: 6.6278e-04\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 3.0315e-04 - val_loss: 4.3679e-04\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 2.4084e-04 - val_loss: 4.1677e-04\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 2.2548e-04 - val_loss: 4.9258e-04\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 2.3347e-04 - val_loss: 4.7847e-04\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 2.2396e-04 - val_loss: 4.3079e-04\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 2.4426e-04 - val_loss: 4.6446e-04\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 2.5664e-04 - val_loss: 5.3903e-04\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 2.4318e-04 - val_loss: 4.6297e-04\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 2.1259e-04 - val_loss: 4.4734e-04\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 2.0867e-04 - val_loss: 6.0885e-04\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 3.3508e-04 - val_loss: 6.9932e-04\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 2.9020e-04 - val_loss: 4.5329e-04\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 2.2717e-04 - val_loss: 4.2801e-04\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 2.1462e-04 - val_loss: 4.2166e-04\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 1.9007e-04 - val_loss: 4.3838e-04\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 1.9185e-04 - val_loss: 4.1675e-04\n",
      "INFO:tensorflow:Assets written to: ../models/facial_landmark_model\\assets\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 150\n",
    "\n",
    "# Run the model\n",
    "cnn_model = create_cnn_model()   \n",
    "run_models(X_train, y_train, X_val, y_val, cnn_model, \"cnn\", NUM_EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
